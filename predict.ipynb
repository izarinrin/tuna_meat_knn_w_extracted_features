{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf29e7e-3acb-450e-963b-55872a6ba0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(img):\n",
    "    global _grade\n",
    "    # Extract features\n",
    "    features = extract_features(img)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "        # print(grade)\n",
    "        _grade = grade\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "def main():\n",
    "    # Set desired camera resolution\n",
    "    desired_width = 1280\n",
    "    desired_height = 720\n",
    "    # Open the default camera (usually the built-in webcam)\n",
    "    cap = cv2.VideoCapture(2)\n",
    "    # cap.set(cv2.CAP_PROP_SETTINGS, 1)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "\n",
    "    # Check if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    # Create a background subtractor object\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame was captured successfully\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "         # Apply background subtraction\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    \n",
    "        # Perform adaptive thresholding to separate foreground from background\n",
    "        _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "        # Invert the thresholded image\n",
    "        thresholded = cv2.bitwise_not(thresholded)\n",
    "    \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the largest contour (if any)\n",
    "        largest_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "\n",
    "        # Draw bounding box around the largest contour (if any)\n",
    "        if largest_contour is not None:\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Zoom in to a specific area inside the bounding box\n",
    "            zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            zoom_size = min(w, h) // zoom_factor\n",
    "            x_zoom = max(0, center_x - zoom_size // 2)\n",
    "            y_zoom = max(0, center_y - zoom_size // 2)\n",
    "            zoomed_image = frame[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "            try:\n",
    "                # Resize the zoomed image to 100x100 pixels\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (400, 400))\n",
    "                cv2.imshow('Zoomed Bounding Box', zoomed_resized)\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "                classify_image(zoomed_resized)\n",
    "                # Draw the outline of the text on the zoomed image\n",
    "                outline_thickness = 2\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "                \n",
    "                # Draw the text on the zoomed image\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                # print(f\"grade = {_grade}\")\n",
    "            except:\n",
    "                 pass\n",
    "\n",
    "        # Display the frame with bounding box (if any)\n",
    "        cv2.imshow('Tuna Grade Prediction Using Knn', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#webcam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bf9d8bf-6c14-4ad9-bf53-55c8f343b56d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Grade: B\n",
      "CPU times: total: 1.97 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#input image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to open file explorer for picking an image\n",
    "def open_file_explorer():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Open file explorer and return the selected file path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "    if file_path:\n",
    "        # If a file is selected, classify the image\n",
    "        predicted_grade = classify_image(file_path)\n",
    "        print(\"Predicted Grade:\", predicted_grade)\n",
    "    else:\n",
    "        print(\"No file selected.\")\n",
    "\n",
    "# Call the function to open file explorer\n",
    "open_file_explorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d65163-1ea0-40eb-95c6-235b30d36828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Processing - CPU Usage: 3.9% | RAM Usage: 216.45 MB\n",
      "Predicted Grade: A\n",
      "Processing Time: 49.96 seconds\n",
      "After Processing - CPU Usage: 9.2% | RAM Usage: 1127.30 MB\n",
      "CPU times: total: 3.64 s\n",
      "Wall time: 55.1 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "#perf evval\n",
    "#input image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import psutil\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Function to log performance metrics (CPU and RAM usage)\n",
    "def log_performance_metrics(stage):\n",
    "    process = psutil.Process(os.getpid())\n",
    "    cpu_usage = psutil.cpu_percent(interval=1)\n",
    "    ram_usage = process.memory_info().rss / 1024 / 1024  # Convert bytes to MB\n",
    "    print(f\"{stage} - CPU Usage: {cpu_usage}% | RAM Usage: {ram_usage:.2f} MB\")\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Tuna Grade Classification Knn', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (500, 500))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to open file explorer for picking an image\n",
    "def open_file_explorer():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Open file explorer and return the selected file path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "     # Measure and log performance before processing\n",
    "    log_performance_metrics(\"Before Processing\")\n",
    "\n",
    "    # Start timing\n",
    "    start_time = time.time()\n",
    "\n",
    "    if file_path:\n",
    "        # If a file is selected, classify the image\n",
    "        predicted_grade = classify_image(file_path)\n",
    "        print(\"Predicted Grade:\", predicted_grade)\n",
    "\n",
    "        # End timing\n",
    "        end_time = time.time()\n",
    "        processing_time = end_time - start_time\n",
    "        print(f\"Processing Time: {processing_time:.2f} seconds\")\n",
    "        \n",
    "        # Measure and log performance after processing\n",
    "        log_performance_metrics(\"After Processing\")\n",
    "    else:\n",
    "        print(\"No file selected.\")\n",
    "\n",
    "# Call the function to open file explorer\n",
    "open_file_explorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef4589b-f3b5-41f1-8a2a-57098d901371",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
