{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7684b3b8-ec9b-4eff-95c4-6fa27b5bf128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file generated\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "# Function to extract features from a single image\n",
    "def extract_features(image):\n",
    "        # If there is no alpha channel, process the entire image\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "        \n",
    "# Directory containing the images\n",
    "directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\toLoad\"  \n",
    "# Replace \"path/to/images\" with the actual path to your image directory\n",
    "\n",
    "# List to store features for all images\n",
    "all_features = []\n",
    "\n",
    "# Iterate over images in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image = cv2.imread(os.path.join(directory, filename), cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # Extract features\n",
    "        r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity = extract_features(image)\n",
    "        \n",
    "        # Determine grading based on filename\n",
    "        if filename.startswith(\"grade_A\"):\n",
    "            grading = \"A\"\n",
    "        elif filename.startswith(\"grade_B\"):\n",
    "            grading = \"B\"\n",
    "        elif filename.startswith(\"grade_C\"):\n",
    "            grading = \"C\"\n",
    "        else:\n",
    "            grading = \"Unknown\"\n",
    "        \n",
    "            \n",
    "        all_features.append({\n",
    "            'grading': grading,\n",
    "            'R': r, \n",
    "            'G': g,\n",
    "            'B': b,\n",
    "            'H_HSV': h_hsv,\n",
    "            'S_HSV': s_hsv,\n",
    "            'V_HSV': v_hsv,\n",
    "            'H_HSI': h_hsi,\n",
    "            'S_HSI': s_hsi,\n",
    "            'I_HSI': i_hsi,\n",
    "            'CONTRAST': contrast,\n",
    "            'CORRELATION': correlation,\n",
    "            'ENERGY': energy,\n",
    "            'HOMOGENEITY': homogeneity\n",
    "        })\n",
    "\n",
    "# Convert all_features list to a DataFrame\n",
    "df = pd.DataFrame(all_features)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('tuna_image_features.csv', index=False)\n",
    "\n",
    "print(\"csv file generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2032d6a8-f197-4aa0-b2d8-7c035f67847e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.934931506849315\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.96      0.91      0.93        95\n",
      "           B       0.91      0.93      0.92        91\n",
      "           C       0.94      0.96      0.95       106\n",
      "\n",
      "    accuracy                           0.93       292\n",
      "   macro avg       0.94      0.93      0.93       292\n",
      "weighted avg       0.94      0.93      0.93       292\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 86   4   5]\n",
      " [  4  85   2]\n",
      " [  0   4 102]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importing libraries  \n",
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp  \n",
    "import pandas as pd  \n",
    "  \n",
    "#importing datasets  \n",
    "data_set= pd.read_csv('test.csv')  \n",
    "  \n",
    "#Extracting Independent and dependent Variable  \n",
    "x= data_set.iloc[:, [1,2,3,4,5,6,7,8,9,10,11,12,13]].values  \n",
    "y= data_set.iloc[:, 0].values  \n",
    "  \n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.20, random_state=42)  \n",
    "  \n",
    "#feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test) \n",
    "\n",
    "#Fitting K-NN classifier to the training set  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train)  \n",
    "\n",
    "#Predicting the test set result  \n",
    "y_pred= classifier.predict(x_test)\n",
    "\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib \n",
    "\n",
    "# Model Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Additional Model Evaluation Metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 7: Save the trained model and the scaler\n",
    "joblib.dump(classifier, 'knn_model.pkl')\n",
    "joblib.dump(st_x, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51051c65-b4d5-47ac-8c32-f9e7ed7ea790",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Grade: A\n"
     ]
    }
   ],
   "source": [
    "#input image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to open file explorer for picking an image\n",
    "def open_file_explorer():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Open file explorer and return the selected file path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "    if file_path:\n",
    "        # If a file is selected, classify the image\n",
    "        predicted_grade = classify_image(file_path)\n",
    "        print(\"Predicted Grade:\", predicted_grade)\n",
    "    else:\n",
    "        print(\"No file selected.\")\n",
    "\n",
    "# Call the function to open file explorer\n",
    "open_file_explorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3437272f-d3df-48e2-befd-6f91177584d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 194\u001b[0m\n\u001b[0;32m    191\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mdestroyAllWindows()\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 194\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 165\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m zoomed_image \u001b[38;5;241m=\u001b[39m frame[y_zoom:y_zoom \u001b[38;5;241m+\u001b[39m zoom_size, x_zoom:x_zoom \u001b[38;5;241m+\u001b[39m zoom_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# Resize the zoomed image to 100x100 pixels\u001b[39;00m\n\u001b[1;32m--> 165\u001b[0m zoomed_resized \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoomed_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# cv2.imshow('Zoomed Bounding Box', zoomed_resized)\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "#input image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(img):\n",
    "    global _grade\n",
    "    # Extract features\n",
    "    features = extract_features(img)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "        # print(grade)\n",
    "        _grade = grade\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "def main():\n",
    "    # Open the default camera (usually the built-in webcam)\n",
    "    cap = cv2.VideoCapture(1)\n",
    "\n",
    "    # Check if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    # Create a background subtractor object\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame was captured successfully\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "        # Find contours in the foreground mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the largest contour (if any)\n",
    "        largest_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "\n",
    "        # Draw bounding box around the largest contour (if any)\n",
    "        if largest_contour is not None:\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Zoom in to a specific area inside the bounding box\n",
    "            zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            zoom_size = min(w, h) // zoom_factor\n",
    "            x_zoom = max(0, center_x - zoom_size // 2)\n",
    "            y_zoom = max(0, center_y - zoom_size // 2)\n",
    "            zoomed_image = frame[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "            # Resize the zoomed image to 100x100 pixels\n",
    "            zoomed_resized = cv2.resize(zoomed_image, (400, 400))\n",
    "            # cv2.imshow('Zoomed Bounding Box', zoomed_resized)\n",
    "            try:\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "                classify_image(zoomed_resized)\n",
    "                # Draw the outline of the text on the zoomed image\n",
    "                outline_thickness = 2\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "                \n",
    "                # Draw the text on the zoomed image\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                # print(f\"grade = {_grade}\")\n",
    "            except:\n",
    "                 pass\n",
    "\n",
    "        # Display the frame with bounding box (if any)\n",
    "        cv2.imshow('Largest Foreground Object', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6524cc-d5c2-4315-9fd7-284cf814a4cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to convert RGB to HSI\n",
    "def rgb_to_hsi(image):\n",
    "    r, g, b = cv2.split(image.astype(float) / 255.0)\n",
    "    intensity = (r + g + b) / 3.0\n",
    "    min_rgb = np.minimum(np.minimum(r, g), b)\n",
    "    saturation = 1 - (3.0 / (r + g + b + 1e-10) * min_rgb)\n",
    "    num = 0.5 * ((r - g) + (r - b))\n",
    "    den = np.sqrt((r - g)**2 + (r - b) * (g - b)) + 1e-10\n",
    "    hue = np.arccos(num / den)\n",
    "    hue[b > g] = 2 * np.pi - hue[b > g]\n",
    "    hue = np.degrees(hue)\n",
    "    # Convert HSI components to uint8\n",
    "    hue = np.uint8(hue)\n",
    "    saturation = np.uint8(saturation * 255)\n",
    "    intensity = np.uint8(intensity * 255)\n",
    "    return cv2.merge([hue, saturation, intensity])\n",
    "\n",
    "\n",
    "# Function to display images\n",
    "def display_images(images, titles):\n",
    "    num_images = len(images)\n",
    "    num_titles = len(titles)\n",
    "    \n",
    "    if num_images != num_titles:\n",
    "        print(\"Number of images does not match number of titles.\")\n",
    "        return\n",
    "    \n",
    "    fig, axes = plt.subplots(1, num_images, figsize=(15, 5))\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        axes[i].imshow(images[i])\n",
    "        axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Directory containing the images\n",
    "directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\toLoad\"  \n",
    "\n",
    "# List to store images\n",
    "images = []\n",
    "\n",
    "# Iterate over images in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image = cv2.imread(os.path.join(directory, filename), cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Convert RGB to HSV\n",
    "        hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "        \n",
    "        # Convert RGB to HSI\n",
    "        hsi_image = cv2.cvtColor(rgb_to_hsi(image), cv2.COLOR_HSV2RGB)\n",
    "        \n",
    "        # Store the images and their titles\n",
    "        images.append(image)\n",
    "        images.append(hsv_image)\n",
    "        images.append(hsi_image)\n",
    "        \n",
    "        # Assuming 'rgb_image', 'hsv_image', and 'hsi_image' are your images\n",
    "        images = [image, hsv_image, hsi_image]\n",
    "        titles = ['RGB', 'HSV', 'HSI']\n",
    "        \n",
    "        # Display the images\n",
    "        display_images(images, titles)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da89ca3-b12d-4814-a91f-47e97e61e726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to extract dominant colors using k-means clustering\n",
    "def get_dominant_colors(image, k=5):\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    kmeans.fit(image)\n",
    "    colors = kmeans.cluster_centers_\n",
    "    return colors\n",
    "\n",
    "# Function to plot the color palette\n",
    "def plot_color_palette(colors, grade, title):\n",
    "    palette = np.zeros((50, 300, 3), dtype=np.uint8)\n",
    "    steps = 300 // colors.shape[0]\n",
    "    for i, color in enumerate(colors):\n",
    "        palette[:, i * steps:(i + 1) * steps, :] = color\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('tuna_image_features.csv')\n",
    "\n",
    "# Assuming your CSV file contains strings that can be evaluated to lists\n",
    "df['rgb'] = df['rgb'].apply(eval)\n",
    "df['hsv'] = df['hsv'].apply(eval)\n",
    "df['hsi'] = df['hsi'].apply(eval)\n",
    "\n",
    "# Dictionary to store images for each grade\n",
    "grade_images = {'A': [], 'B': [], 'C': []}\n",
    "\n",
    "# Iterate over the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    grading = row['grading']\n",
    "    rgb = np.array(row['rgb'])\n",
    "    hsv = np.array(row['hsv'])\n",
    "    hsi = np.array(row['hsi'])\n",
    "\n",
    "    # Store the image in the corresponding grade list\n",
    "    if grading in grade_images:\n",
    "        grade_images[grading].append({'rgb': rgb, 'hsv': hsv, 'hsi': hsi})\n",
    "\n",
    "# Generate and display color palettes for each grade\n",
    "for grade, images in grade_images.items():\n",
    "    if images:\n",
    "        # Combine all images of the same grade into one array for each feature\n",
    "        combined_rgb = np.vstack([image['rgb'] for image in images])\n",
    "        combined_hsv = np.vstack([image['hsv'] for image in images])\n",
    "        combined_hsi = np.vstack([image['hsi'] for image in images])\n",
    "\n",
    "        # Get dominant colors for each feature\n",
    "        dominant_colors_rgb = get_dominant_colors(combined_rgb)\n",
    "        dominant_colors_hsv = get_dominant_colors(combined_hsv)\n",
    "        dominant_colors_hsi = get_dominant_colors(combined_hsi)\n",
    "\n",
    "        # Plot color palettes for each feature\n",
    "        plot_color_palette(dominant_colors_rgb, grade, f\"RGB Color Palette for Grade {grade}\")\n",
    "        plot_color_palette(dominant_colors_hsv, grade, f\"HSV Color Palette for Grade {grade}\")\n",
    "        plot_color_palette(dominant_colors_hsi, grade, f\"HSI Color Palette for Grade {grade}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
