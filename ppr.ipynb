{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caeaa2e9-83c2-42b6-85a7-b81d919c1ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accurate\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "    # Your rgb_to_hsi function code here\n",
    "\n",
    "def extract_features(image):\n",
    "    # Your extract_features function code here\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(image)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to open file explorer for picking an image\n",
    "def open_file_explorer():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Open file explorer and return the selected file path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "    if file_path:\n",
    "        # If a file is selected, classify the image\n",
    "        predicted_grade = classify_image(file_path)\n",
    "        print(\"Predicted Grade:\", predicted_grade)\n",
    "    else:\n",
    "        print(\"No file selected.\")\n",
    "\n",
    "# Call the function to open file explorer\n",
    "open_file_explorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fca86c02-5c37-4b84-a239-b750a00f5f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cropped zoom images within bounding boxes saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\4ppr output\n"
     ]
    }
   ],
   "source": [
    "#for paper\n",
    "\n",
    "#zoom gA\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Function to crop zoom the image within the bounding box and resize to a uniform size\n",
    "def crop_zoom(image, x, y, w, h, zoom_factor=1.2, output_size=(800, 800)):\n",
    "    # Calculate the zoomed area\n",
    "    new_w = int(w / zoom_factor)\n",
    "    new_h = int(h / zoom_factor)\n",
    "    \n",
    "    # Ensure the coordinates are within image boundaries\n",
    "    start_x = max(x + (w - new_w) // 2, 0)\n",
    "    start_y = max(y + (h - new_h) // 2, 0)\n",
    "    end_x = min(start_x + new_w, image.shape[1])\n",
    "    end_y = min(start_y + new_h, image.shape[0])\n",
    "    \n",
    "    # Crop the image to the zoomed area\n",
    "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "\n",
    "    output_file_path = os.path.join(target_directory, \"cropped.jpg\")\n",
    "    cv2.imwrite(output_file_path, cropped_image)\n",
    "    \n",
    "    # Resize the cropped image to the desired output size\n",
    "    resized_image = cv2.resize(cropped_image, output_size)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "# Function to detect objects and get bounding box\n",
    "def detect_and_draw_boxes(frame):\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    output_file_path = os.path.join(target_directory, \"gray.jpg\")\n",
    "    cv2.imwrite(output_file_path, gray)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "    output_file_path = os.path.join(target_directory, \"blurred.jpg\")\n",
    "    cv2.imwrite(output_file_path, blurred)\n",
    "    \n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    output_file_path = os.path.join(target_directory, \"thresholded.jpg\")\n",
    "    cv2.imwrite(output_file_path, thresholded)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # output_file_path = os.path.join(target_directory, \"contour.jpg\")\n",
    "        # cv2.imwrite(output_file_path, main_contour)\n",
    "        \n",
    "        # Get bounding box coordinates around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        return x, y, w, h, frame\n",
    "    else:\n",
    "        return None, None, None, None, frame\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\4ppr\"\n",
    "\n",
    "# Target directory for cropped zoom images\n",
    "target_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\4ppr output\"\n",
    "\n",
    "# Zoom factor and output size\n",
    "zoom_factor = 1.2\n",
    "output_size = (800, 800)\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate over images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "        # Load the image\n",
    "        input_file_path = os.path.join(source_directory, filename)\n",
    "        image = cv2.imread(input_file_path)\n",
    "        \n",
    "        # Detect objects and get bounding box coordinates\n",
    "        x, y, w, h, detected_image = detect_and_draw_boxes(image.copy())\n",
    "        \n",
    "        if x is not None and y is not None and w is not None and h is not None:\n",
    "            # Zoom in within the bounding box and resize to uniform size\n",
    "            zoomed_resized_image = crop_zoom(detected_image, x, y, w, h, zoom_factor, output_size)\n",
    "            zoomed_output_file_path = os.path.join(target_directory, \"grade_A_\" + os.path.splitext(filename)[0] + \"_zoom.jpg\")\n",
    "            cv2.imwrite(zoomed_output_file_path, zoomed_resized_image)\n",
    "\n",
    "print(\"All cropped zoom images within bounding boxes saved to:\", target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5f77fcd-8094-469f-990a-c5f4cbf1c932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images processed and saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\4ppr output\\op2\n"
     ]
    }
   ],
   "source": [
    "#working resize turn bg tro black\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to load, resize, and remove background from an image\n",
    "def load_resize_remove_background(file_path, target_size):\n",
    "    # Load the image\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    # Resize the image to target size\n",
    "    resized_image = cv2.resize(image, (target_size, target_size))\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a mask to store the foreground pixels\n",
    "    mask = np.zeros_like(gray)\n",
    "\n",
    "    # Draw contours on the mask\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Bitwise AND operation to extract foreground\n",
    "    foreground = cv2.bitwise_and(resized_image, resized_image, mask=mask)\n",
    "\n",
    "    # Set the background to black\n",
    "    background_mask = (mask == 0)\n",
    "    foreground[background_mask] = [0, 0, 0]\n",
    "    \n",
    "    return foreground\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\4ppr output\\op1\"  # Replace with the actual path to your source image directory\n",
    "\n",
    "# Target directory for resized images\n",
    "target_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\4ppr output\\op2\"  # Replace with the desired output directory for resized images\n",
    "\n",
    "# Target size for resizing (square)\n",
    "target_size = 300\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate over images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):  # Look for JPEG files\n",
    "        # Load, resize, and remove background from the image\n",
    "        input_file_path = os.path.join(source_directory, filename)\n",
    "        processed_image = load_resize_remove_background(input_file_path, target_size)\n",
    "        \n",
    "        if processed_image is not None:\n",
    "            # Save the original size processed image\n",
    "            original_output_file_path = os.path.join(target_directory, os.path.splitext(filename)[0] + \"_processed.png\")\n",
    "            cv2.imwrite(original_output_file_path, processed_image)\n",
    "\n",
    "print(\"All images processed and saved to:\", target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e8cac8-aa38-4239-9ba3-d25b96e8b3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: IMG20220515184251.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184251_01.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184254.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184255.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184256.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184258.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184304.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184306.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184307.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184308.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184309.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184310.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184311.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184313.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184314.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184316.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184318.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184320.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184322.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184323.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184324.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184401.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184403.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184405.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184407.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184408.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184409.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184411.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184413.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184425.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184426.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184429.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184431.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184432.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184434.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121621.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121623.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121625.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121628.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121629.jpg - Predicted Grade: A\n",
      "Processing Time - Min: 1.0832500457763672 Max: 2.2864434719085693 Mean: 1.4602328300476075\n",
      "CPU Usage - Min: 133.3 Max: 169.4 Mean: 154.895\n",
      "RAM Usage - Min: 58359808 Max: 1013559296 Mean: 84558643.2\n",
      "B done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img) / 255\n",
    "\n",
    "        # Separate color channels\n",
    "        blue = bgr[:, :, 0]\n",
    "        green = bgr[:, :, 1]\n",
    "        red = bgr[:, :, 2]\n",
    "\n",
    "        # Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        # Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        # Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                          ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        # Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "    # if zero dont input\n",
    "    if np.any(image != [0, 0, 0]):\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "        rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        # Convert to grayscale for GLCM\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Convert RGB to HSI\n",
    "        hsi = rgb_to_hsi(image)\n",
    "\n",
    "        # RGB\n",
    "        r, g, b = np.mean(rgb[:, :, 0]), np.mean(rgb[:, :, 1]), np.mean(rgb[:, :, 2])\n",
    "\n",
    "        # HSV\n",
    "        h_hsv, s_hsv, v_hsv = np.mean(hsv[:, :, 0]), np.mean(hsv[:, :, 1]), np.mean(hsv[:, :, 2])\n",
    "\n",
    "        # HSI (HLS approximation)\n",
    "        h_hsi, s_hsi, i_hsi = np.mean(hsi[:, :, 0]), np.mean(hsi[:, :, 1]), np.mean(hsi[:, :, 2])\n",
    "\n",
    "        # GLCM\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi / 4, np.pi / 2, 3 * np.pi / 4],\n",
    "                            symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "\n",
    "        return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "    else:\n",
    "        return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "\n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_memory = process.memory_info().rss\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        end_time = time.time()\n",
    "        end_cpu = process.cpu_percent(interval=None)\n",
    "        end_memory = process.memory_info().rss\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        cpu_usage = end_cpu - start_cpu\n",
    "        ram_usage = end_memory - start_memory\n",
    "\n",
    "        return grade[0], processing_time, cpu_usage, ram_usage\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\", 0, 0, 0\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    processing_times = []\n",
    "    cpu_usages = []\n",
    "    ram_usages = []\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade, processing_time, cpu_usage, ram_usage = classify_and_save_image(image_path, output_folder)\n",
    "            processing_times.append(processing_time)\n",
    "            cpu_usages.append(cpu_usage)\n",
    "            ram_usages.append(ram_usage)\n",
    "            print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "    \n",
    "    print(\"Processing Time - Min:\", np.min(processing_times), \"Max:\", np.max(processing_times), \"Mean:\", np.mean(processing_times))\n",
    "    print(\"CPU Usage - Min:\", np.min(cpu_usages), \"Max:\", np.max(cpu_usages), \"Mean:\", np.mean(cpu_usages))\n",
    "    print(\"RAM Usage - Min:\", np.min(ram_usages), \"Max:\", np.max(ram_usages), \"Mean:\", np.mean(ram_usages))\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\val output2\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"B done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1afa9bf3-4d1f-49dc-a04f-2dd680298201",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: IMG20220515184251.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184251_01.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184254.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184255.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184256.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184258.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184304.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184306.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184307.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184308.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184309.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184310.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184311.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184313.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184314.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184316.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184318.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184320.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184322.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184323.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184324.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184401.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184403.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184405.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184407.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184408.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184409.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184411.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184413.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184425.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184426.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184429.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184431.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184432.jpg - Predicted Grade: B\n",
      "Image: IMG20220515184434.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121621.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121623.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121625.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121628.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121629.jpg - Predicted Grade: A\n",
      "Processing Time - Min: 1.0760016441345215 Max: 2.2459981441497803 Mean: 1.4695504248142242\n",
      "CPU Usage (%) - Min: 16.9 Max: 23.4125 Mean: 19.348750000000003\n",
      "RAM Usage (MB) - Min: 54.82421875 Max: 966.4140625 Mean: 80.74912109375\n",
      "B done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img) / 255\n",
    "\n",
    "        # Separate color channels\n",
    "        blue = bgr[:, :, 0]\n",
    "        green = bgr[:, :, 1]\n",
    "        red = bgr[:, :, 2]\n",
    "\n",
    "        # Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        # Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        # Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                          ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        # Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "    # if zero dont input\n",
    "    if np.any(image != [0, 0, 0]):\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "        rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        # Convert to grayscale for GLCM\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Convert RGB to HSI\n",
    "        hsi = rgb_to_hsi(image)\n",
    "\n",
    "        # RGB\n",
    "        r, g, b = np.mean(rgb[:, :, 0]), np.mean(rgb[:, :, 1]), np.mean(rgb[:, :, 2])\n",
    "\n",
    "        # HSV\n",
    "        h_hsv, s_hsv, v_hsv = np.mean(hsv[:, :, 0]), np.mean(hsv[:, :, 1]), np.mean(hsv[:, :, 2])\n",
    "\n",
    "        # HSI (HLS approximation)\n",
    "        h_hsi, s_hsi, i_hsi = np.mean(hsi[:, :, 0]), np.mean(hsi[:, :, 1]), np.mean(hsi[:, :, 2])\n",
    "\n",
    "        # GLCM\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi / 4, np.pi / 2, 3 * np.pi / 4],\n",
    "                            symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "\n",
    "        return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "    else:\n",
    "        return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "\n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_memory = process.memory_info().rss\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        end_time = time.time()\n",
    "        end_cpu = process.cpu_percent(interval=None)\n",
    "        end_memory = process.memory_info().rss\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        cpu_usage = (end_cpu - start_cpu) / psutil.cpu_count()  # Convert to percent\n",
    "        ram_usage = (end_memory - start_memory) / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        return grade[0], processing_time, cpu_usage, ram_usage\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\", 0, 0, 0\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    processing_times = []\n",
    "    cpu_usages = []\n",
    "    ram_usages = []\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade, processing_time, cpu_usage, ram_usage = classify_and_save_image(image_path, output_folder)\n",
    "            processing_times.append(processing_time)\n",
    "            cpu_usages.append(cpu_usage)\n",
    "            ram_usages.append(ram_usage)\n",
    "            print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "    \n",
    "    print(\"Processing Time - Min:\", np.min(processing_times), \"Max:\", np.max(processing_times), \"Mean:\", np.mean(processing_times))\n",
    "    print(\"CPU Usage (%) - Min:\", np.min(cpu_usages), \"Max:\", np.max(cpu_usages), \"Mean:\", np.mean(cpu_usages))\n",
    "    print(\"RAM Usage (MB) - Min:\", np.min(ram_usages), \"Max:\", np.max(ram_usages), \"Mean:\", np.mean(ram_usages))\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\val output2\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"B done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9b17f1-e4f1-4baf-b828-147494fb95ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: IMG20220516121036.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121039.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121040.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121042.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121043.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121044.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121045.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121048.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121051.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121054.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121055.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121057.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121058.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121059.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121100.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121102.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121104.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121105.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121106.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121108.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121136.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121138.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121142.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121143.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121145.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121146.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121147.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121148.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121150.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121151.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121151_01.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121154.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121156.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121159.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121203.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121204.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121206.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121208.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121209.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121214.jpg - Predicted Grade: A\n",
      "Processing Time - Min: 1.1002001762390137 Max: 1.822880744934082 Mean: 1.3704544007778168\n",
      "CPU Usage (%) - Min: 16.775 Max: 23.425 Mean: 20.0146875\n",
      "RAM Usage (MB) - Min: 53.80078125 Max: 966.359375 Mean: 79.62744140625\n",
      "B done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img) / 255\n",
    "\n",
    "        # Separate color channels\n",
    "        blue = bgr[:, :, 0]\n",
    "        green = bgr[:, :, 1]\n",
    "        red = bgr[:, :, 2]\n",
    "\n",
    "        # Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        # Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        # Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                          ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        # Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "    # if zero dont input\n",
    "    if np.any(image != [0, 0, 0]):\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "        rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        # Convert to grayscale for GLCM\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Convert RGB to HSI\n",
    "        hsi = rgb_to_hsi(image)\n",
    "\n",
    "        # RGB\n",
    "        r, g, b = np.mean(rgb[:, :, 0]), np.mean(rgb[:, :, 1]), np.mean(rgb[:, :, 2])\n",
    "\n",
    "        # HSV\n",
    "        h_hsv, s_hsv, v_hsv = np.mean(hsv[:, :, 0]), np.mean(hsv[:, :, 1]), np.mean(hsv[:, :, 2])\n",
    "\n",
    "        # HSI (HLS approximation)\n",
    "        h_hsi, s_hsi, i_hsi = np.mean(hsi[:, :, 0]), np.mean(hsi[:, :, 1]), np.mean(hsi[:, :, 2])\n",
    "\n",
    "        # GLCM\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi / 4, np.pi / 2, 3 * np.pi / 4],\n",
    "                            symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "\n",
    "        return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "    else:\n",
    "        return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "\n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_memory = process.memory_info().rss\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        end_time = time.time()\n",
    "        end_cpu = process.cpu_percent(interval=None)\n",
    "        end_memory = process.memory_info().rss\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        cpu_usage = (end_cpu - start_cpu) / psutil.cpu_count()  # Convert to percent\n",
    "        ram_usage = (end_memory - start_memory) / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        return grade[0], processing_time, cpu_usage, ram_usage\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\", 0, 0, 0\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    processing_times = []\n",
    "    cpu_usages = []\n",
    "    ram_usages = []\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade, processing_time, cpu_usage, ram_usage = classify_and_save_image(image_path, output_folder)\n",
    "            processing_times.append(processing_time)\n",
    "            cpu_usages.append(cpu_usage)\n",
    "            ram_usages.append(ram_usage)\n",
    "            print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "    \n",
    "    print(\"Processing Time - Min:\", np.min(processing_times), \"Max:\", np.max(processing_times), \"Mean:\", np.mean(processing_times))\n",
    "    print(\"CPU Usage (%) - Min:\", np.min(cpu_usages), \"Max:\", np.max(cpu_usages), \"Mean:\", np.mean(cpu_usages))\n",
    "    print(\"RAM Usage (MB) - Min:\", np.min(ram_usages), \"Max:\", np.max(ram_usages), \"Mean:\", np.mean(ram_usages))\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE A\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE A\\val output2\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"B done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a1257f6-e7e0-49a9-8af5-42f05e7ab6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image: IMG20220515183513.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183514.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183515.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183517.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183807.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183809.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183811.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183812.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183813.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183815.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183817.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183819.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183820.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183821.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183822.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183823.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183825.jpg - Predicted Grade: C\n",
      "Image: IMG20220515183826.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121850.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121851.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121852.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121854.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121855.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121856.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121859.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121901.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121902.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121903.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121932.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121933.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121935.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121936.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121938.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121939.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121942.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121943.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121946.jpg - Predicted Grade: B\n",
      "Image: IMG20220516121950.jpg - Predicted Grade: C\n",
      "Image: IMG20220516121951.jpg - Predicted Grade: A\n",
      "Image: IMG20220516121952.jpg - Predicted Grade: A\n",
      "Processing Time - Min: 1.0810034275054932 Max: 1.935999870300293 Mean: 1.4270384192466736\n",
      "CPU Usage (%) - Min: 17.5375 Max: 22.3875 Mean: 19.973125\n",
      "RAM Usage (MB) - Min: 54.234375 Max: 966.97265625 Mean: 80.96025390625\n",
      "B done\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        # Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img) / 255\n",
    "\n",
    "        # Separate color channels\n",
    "        blue = bgr[:, :, 0]\n",
    "        green = bgr[:, :, 1]\n",
    "        red = bgr[:, :, 2]\n",
    "\n",
    "        # Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        # Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        # Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                          ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        # Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "    # if zero dont input\n",
    "    if np.any(image != [0, 0, 0]):\n",
    "        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "        rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "\n",
    "        # Convert RGB to HSV\n",
    "        hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        # Convert to grayscale for GLCM\n",
    "        gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # Convert RGB to HSI\n",
    "        hsi = rgb_to_hsi(image)\n",
    "\n",
    "        # RGB\n",
    "        r, g, b = np.mean(rgb[:, :, 0]), np.mean(rgb[:, :, 1]), np.mean(rgb[:, :, 2])\n",
    "\n",
    "        # HSV\n",
    "        h_hsv, s_hsv, v_hsv = np.mean(hsv[:, :, 0]), np.mean(hsv[:, :, 1]), np.mean(hsv[:, :, 2])\n",
    "\n",
    "        # HSI (HLS approximation)\n",
    "        h_hsi, s_hsi, i_hsi = np.mean(hsi[:, :, 0]), np.mean(hsi[:, :, 1]), np.mean(hsi[:, :, 2])\n",
    "\n",
    "        # GLCM\n",
    "        glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi / 4, np.pi / 2, 3 * np.pi / 4],\n",
    "                            symmetric=True, normed=True)\n",
    "        contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "        correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "        energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "        homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "\n",
    "        return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "    else:\n",
    "        return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "\n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    start_time = time.time()\n",
    "    process = psutil.Process(os.getpid())\n",
    "    start_cpu = process.cpu_percent(interval=None)\n",
    "    start_memory = process.memory_info().rss\n",
    "\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        end_time = time.time()\n",
    "        end_cpu = process.cpu_percent(interval=None)\n",
    "        end_memory = process.memory_info().rss\n",
    "\n",
    "        processing_time = end_time - start_time\n",
    "        cpu_usage = (end_cpu - start_cpu) / psutil.cpu_count()  # Convert to percent\n",
    "        ram_usage = (end_memory - start_memory) / (1024 * 1024)  # Convert to MB\n",
    "\n",
    "        return grade[0], processing_time, cpu_usage, ram_usage\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\", 0, 0, 0\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    processing_times = []\n",
    "    cpu_usages = []\n",
    "    ram_usages = []\n",
    "\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade, processing_time, cpu_usage, ram_usage = classify_and_save_image(image_path, output_folder)\n",
    "            processing_times.append(processing_time)\n",
    "            cpu_usages.append(cpu_usage)\n",
    "            ram_usages.append(ram_usage)\n",
    "            print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "    \n",
    "    print(\"Processing Time - Min:\", np.min(processing_times), \"Max:\", np.max(processing_times), \"Mean:\", np.mean(processing_times))\n",
    "    print(\"CPU Usage (%) - Min:\", np.min(cpu_usages), \"Max:\", np.max(cpu_usages), \"Mean:\", np.mean(cpu_usages))\n",
    "    print(\"RAM Usage (MB) - Min:\", np.min(ram_usages), \"Max:\", np.max(ram_usages), \"Mean:\", np.mean(ram_usages))\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE C\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE C\\val output2\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"B done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec17bf5-9fa8-4893-9358-d11abfcc5fe8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
