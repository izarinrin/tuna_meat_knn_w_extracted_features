{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0692f0ce-bf5c-44b6-bfe6-e132a5df5b7c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (4.9.0.80)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (0.22.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (3.8.4)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp39-cp39-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from opencv-python) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (1.13.0)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (3.2.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (10.3.0)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (2.34.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (2024.2.12)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (23.2)\n",
      "Requirement already satisfied: lazy_loader>=0.3 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from scikit-image) (0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from matplotlib) (6.4.0)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.17.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\anaconda3\\envs\\tunaknn-env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading scikit_learn-1.5.0-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB 991.0 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.2/11.0 MB 3.6 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 0.7/11.0 MB 6.3 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 1.7/11.0 MB 9.7 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 13.1 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.1/11.0 MB 15.3 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.3/11.0 MB 17.0 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 19.0 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.8/11.0 MB 19.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 9.9/11.0 MB 19.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 24.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 23.4 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "   ---------------------------------------- 0.0/301.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 301.8/301.8 kB 19.4 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python scikit-image pandas matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a14220b-e3d1-4b74-a558-20c09583f7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cropped zoom images within bounding boxes saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\n",
      "CPU times: total: 3min 9s\n",
      "Wall time: 50.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#zoom gA\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create background subtractor object\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to crop zoom the image within the bounding box and resize to a uniform size\n",
    "def crop_zoom(image, x, y, w, h, zoom_factor=1.2, output_size=(800, 800)):\n",
    "    # Calculate the zoomed area\n",
    "    new_w = int(w / zoom_factor)\n",
    "    new_h = int(h / zoom_factor)\n",
    "    \n",
    "    # Ensure the coordinates are within image boundaries\n",
    "    start_x = max(x + (w - new_w) // 2, 0)\n",
    "    start_y = max(y + (h - new_h) // 2, 0)\n",
    "    end_x = min(start_x + new_w, image.shape[1])\n",
    "    end_y = min(start_y + new_h, image.shape[0])\n",
    "    \n",
    "    # Crop the image to the zoomed area\n",
    "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    # Resize the cropped image to the desired output size\n",
    "    resized_image = cv2.resize(cropped_image, output_size)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "# Function to detect objects and get bounding box\n",
    "def detect_and_draw_boxes(frame):\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    \n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get bounding box coordinates around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        return x, y, w, h, frame\n",
    "    else:\n",
    "        return None, None, None, None, frame\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE A\\training\"\n",
    "\n",
    "# Target directory for cropped zoom images\n",
    "target_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\"\n",
    "\n",
    "# Zoom factor and output size\n",
    "zoom_factor = 1.2\n",
    "output_size = (800, 800)\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate over images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "        # Load the image\n",
    "        input_file_path = os.path.join(source_directory, filename)\n",
    "        image = cv2.imread(input_file_path)\n",
    "        \n",
    "        # Detect objects and get bounding box coordinates\n",
    "        x, y, w, h, detected_image = detect_and_draw_boxes(image.copy())\n",
    "        \n",
    "        if x is not None and y is not None and w is not None and h is not None:\n",
    "            # Zoom in within the bounding box and resize to uniform size\n",
    "            zoomed_resized_image = crop_zoom(detected_image, x, y, w, h, zoom_factor, output_size)\n",
    "            zoomed_output_file_path = os.path.join(target_directory, \"grade_A_\" + os.path.splitext(filename)[0] + \"_zoom.jpg\")\n",
    "            cv2.imwrite(zoomed_output_file_path, zoomed_resized_image)\n",
    "\n",
    "print(\"All cropped zoom images within bounding boxes saved to:\", target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c9dea78-cab0-42fe-b84a-f5a8cc9167f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cropped zoom images within bounding boxes saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\n",
      "CPU times: total: 3min 52s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#zoom gB\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create background subtractor object\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to crop zoom the image within the bounding box and resize to a uniform size\n",
    "def crop_zoom(image, x, y, w, h, zoom_factor=1.2, output_size=(800, 800)):\n",
    "    # Calculate the zoomed area\n",
    "    new_w = int(w / zoom_factor)\n",
    "    new_h = int(h / zoom_factor)\n",
    "    \n",
    "    # Ensure the coordinates are within image boundaries\n",
    "    start_x = max(x + (w - new_w) // 2, 0)\n",
    "    start_y = max(y + (h - new_h) // 2, 0)\n",
    "    end_x = min(start_x + new_w, image.shape[1])\n",
    "    end_y = min(start_y + new_h, image.shape[0])\n",
    "    \n",
    "    # Crop the image to the zoomed area\n",
    "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    # Resize the cropped image to the desired output size\n",
    "    resized_image = cv2.resize(cropped_image, output_size)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "# Function to detect objects and get bounding box\n",
    "def detect_and_draw_boxes(frame):\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    \n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get bounding box coordinates around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        return x, y, w, h, frame\n",
    "    else:\n",
    "        return None, None, None, None, frame\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\training\"\n",
    "\n",
    "# Target directory for cropped zoom images\n",
    "target_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\"\n",
    "\n",
    "# Zoom factor and output size\n",
    "zoom_factor = 1.2\n",
    "output_size = (800, 800)\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate over images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "        # Load the image\n",
    "        input_file_path = os.path.join(source_directory, filename)\n",
    "        image = cv2.imread(input_file_path)\n",
    "        \n",
    "        # Detect objects and get bounding box coordinates\n",
    "        x, y, w, h, detected_image = detect_and_draw_boxes(image.copy())\n",
    "        \n",
    "        if x is not None and y is not None and w is not None and h is not None:\n",
    "            # Zoom in within the bounding box and resize to uniform size\n",
    "            zoomed_resized_image = crop_zoom(detected_image, x, y, w, h, zoom_factor, output_size)\n",
    "            zoomed_output_file_path = os.path.join(target_directory, \"grade_B_\" + os.path.splitext(filename)[0] + \"_zoom.jpg\")\n",
    "            cv2.imwrite(zoomed_output_file_path, zoomed_resized_image)\n",
    "\n",
    "print(\"All cropped zoom images within bounding boxes saved to:\", target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a14dd579-2f0d-453b-a761-de5fa7ba79d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cropped zoom images within bounding boxes saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\n",
      "CPU times: total: 3min 49s\n",
      "Wall time: 59.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#zoom gC\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Create background subtractor object\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to crop zoom the image within the bounding box and resize to a uniform size\n",
    "def crop_zoom(image, x, y, w, h, zoom_factor=1.2, output_size=(800, 800)):\n",
    "    # Calculate the zoomed area\n",
    "    new_w = int(w / zoom_factor)\n",
    "    new_h = int(h / zoom_factor)\n",
    "    \n",
    "    # Ensure the coordinates are within image boundaries\n",
    "    start_x = max(x + (w - new_w) // 2, 0)\n",
    "    start_y = max(y + (h - new_h) // 2, 0)\n",
    "    end_x = min(start_x + new_w, image.shape[1])\n",
    "    end_y = min(start_y + new_h, image.shape[0])\n",
    "    \n",
    "    # Crop the image to the zoomed area\n",
    "    cropped_image = image[start_y:end_y, start_x:end_x]\n",
    "    \n",
    "    # Resize the cropped image to the desired output size\n",
    "    resized_image = cv2.resize(cropped_image, output_size)\n",
    "    \n",
    "    return resized_image\n",
    "\n",
    "# Function to detect objects and get bounding box\n",
    "def detect_and_draw_boxes(frame):\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(frame)\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    \n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "    \n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        # Get bounding box coordinates around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        return x, y, w, h, frame\n",
    "    else:\n",
    "        return None, None, None, None, frame\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE C\\training\"\n",
    "\n",
    "# Target directory for cropped zoom images\n",
    "target_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\"\n",
    "\n",
    "# Zoom factor and output size\n",
    "zoom_factor = 1.2\n",
    "output_size = (800, 800)\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate over images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "        # Load the image\n",
    "        input_file_path = os.path.join(source_directory, filename)\n",
    "        image = cv2.imread(input_file_path)\n",
    "        \n",
    "        # Detect objects and get bounding box coordinates\n",
    "        x, y, w, h, detected_image = detect_and_draw_boxes(image.copy())\n",
    "        \n",
    "        if x is not None and y is not None and w is not None and h is not None:\n",
    "            # Zoom in within the bounding box and resize to uniform size\n",
    "            zoomed_resized_image = crop_zoom(detected_image, x, y, w, h, zoom_factor, output_size)\n",
    "            zoomed_output_file_path = os.path.join(target_directory, \"grade_C_\" + os.path.splitext(filename)[0] + \"_zoom.jpg\")\n",
    "            cv2.imwrite(zoomed_output_file_path, zoomed_resized_image)\n",
    "\n",
    "print(\"All cropped zoom images within bounding boxes saved to:\", target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71fa20e-f20e-4776-ab97-2e4ae75121ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images processed and saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro2\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 12.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#working resize turn bg tro black\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to load, resize, and remove background from an image\n",
    "def load_resize_remove_background(file_path, target_size):\n",
    "    # Load the image\n",
    "    image = cv2.imread(file_path, cv2.IMREAD_UNCHANGED)\n",
    "    if image is None:\n",
    "        return None\n",
    "    \n",
    "    # Resize the image to target size\n",
    "    resized_image = cv2.resize(image, (target_size, target_size))\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Create a mask to store the foreground pixels\n",
    "    mask = np.zeros_like(gray)\n",
    "\n",
    "    # Draw contours on the mask\n",
    "    cv2.drawContours(mask, contours, -1, (255), thickness=cv2.FILLED)\n",
    "\n",
    "    # Bitwise AND operation to extract foreground\n",
    "    foreground = cv2.bitwise_and(resized_image, resized_image, mask=mask)\n",
    "\n",
    "    # Set the background to black\n",
    "    background_mask = (mask == 0)\n",
    "    foreground[background_mask] = [0, 0, 0]\n",
    "    \n",
    "    return foreground\n",
    "\n",
    "# Source directory containing the images\n",
    "source_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro1\"  # Replace with the actual path to your source image directory\n",
    "\n",
    "# Target directory for resized images\n",
    "target_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro2\"  # Replace with the desired output directory for resized images\n",
    "\n",
    "# Target size for resizing (square)\n",
    "target_size = 300\n",
    "\n",
    "# Create the target directory if it doesn't exist\n",
    "if not os.path.exists(target_directory):\n",
    "    os.makedirs(target_directory)\n",
    "\n",
    "# Iterate over images in the source directory\n",
    "for filename in os.listdir(source_directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):  # Look for JPEG files\n",
    "        # Load, resize, and remove background from the image\n",
    "        input_file_path = os.path.join(source_directory, filename)\n",
    "        processed_image = load_resize_remove_background(input_file_path, target_size)\n",
    "        \n",
    "        if processed_image is not None:\n",
    "            # Save the original size processed image\n",
    "            original_output_file_path = os.path.join(target_directory, os.path.splitext(filename)[0] + \"_processed.png\")\n",
    "            cv2.imwrite(original_output_file_path, processed_image)\n",
    "\n",
    "print(\"All images processed and saved to:\", target_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e47ed864-bcce-4a37-9c8f-9864538520b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images processed and saved to: C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\toLoad\n",
      "CPU times: total: 3.03 s\n",
      "Wall time: 6.34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Function to crop image at specified coordinates\n",
    "def crop_image(image, x, y, width, height):\n",
    "    return image[y:y+height, x:x+width]\n",
    "\n",
    "# Function to check if an image contains black pixels\n",
    "def has_black_pixels(image):\n",
    "    return np.any(np.all(image == [0, 0, 0], axis=-1))\n",
    "\n",
    "# Function to generate ROIs covering the entire image\n",
    "def generate_rois(image, crop_size):\n",
    "    height, width, _ = image.shape\n",
    "    rois = []\n",
    "    step_size = crop_size // 2\n",
    "    for y in range(0, height - crop_size + 1, step_size):\n",
    "        for x in range(0, width - crop_size + 1, step_size):\n",
    "            rois.append({\"x\": x, \"y\": y, \"width\": crop_size, \"height\": crop_size})\n",
    "    return rois\n",
    "\n",
    "# Directory containing the images\n",
    "directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\prepro2\"\n",
    "# Output directory for cropped images\n",
    "output_directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\toLoad\"\n",
    "# Size of the cropped regions\n",
    "crop_size = 32\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Iterate over images in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image = cv2.imread(os.path.join(directory, filename))\n",
    "        \n",
    "        # Check if the image is loaded successfully\n",
    "        if image is None:\n",
    "            print(f\"Error loading image {filename}\")\n",
    "            continue\n",
    "        \n",
    "        # Generate ROIs covering the entire image\n",
    "        rois = generate_rois(image, crop_size)\n",
    "        \n",
    "        # Initialize list for non-black cropped images\n",
    "        non_black_crops = []\n",
    "        \n",
    "        # Crop images in the specified ROIs\n",
    "        for roi in rois:\n",
    "            cropped_image = crop_image(image, roi[\"x\"], roi[\"y\"], roi[\"width\"], roi[\"height\"])\n",
    "            \n",
    "            # Check if the cropped region contains any black pixels\n",
    "            if not has_black_pixels(cropped_image):\n",
    "                non_black_crops.append(cropped_image)\n",
    "                \n",
    "                # If we have enough non-black crops, break\n",
    "                if len(non_black_crops) >= 3:\n",
    "                    break\n",
    "        \n",
    "        # If there are not enough non-black crops, fill with whatever is available\n",
    "        while len(non_black_crops) < 3:\n",
    "            for roi in rois:\n",
    "                cropped_image = crop_image(image, roi[\"x\"], roi[\"y\"], roi[\"width\"], roi[\"height\"])\n",
    "                non_black_crops.append(cropped_image)\n",
    "                if len(non_black_crops) >= 3:\n",
    "                    break\n",
    "\n",
    "        # Save exactly 3 cropped images\n",
    "        for i, cropped_image in enumerate(non_black_crops[:3]):\n",
    "            output_filename = os.path.join(output_directory, f\"{filename.split('.')[0]}_crop_{i+1}.png\")\n",
    "            cv2.imwrite(output_filename, cropped_image)\n",
    "            # print(f\"Image {filename} cropped and saved as {output_filename}\")\n",
    "\n",
    "print(\"All images processed and saved to:\", output_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55f07b0e-4a9a-4318-b391-be8ee6d808df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv file generated\n",
      "CPU times: total: 1min 8s\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from skimage.feature.texture import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "# Function to extract features from a single image\n",
    "def extract_features(image):\n",
    "        # If there is no alpha channel, process the entire image\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "        \n",
    "# Directory containing the images\n",
    "directory = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\toLoad\"  \n",
    "# Replace \"path/to/images\" with the actual path to your image directory\n",
    "\n",
    "# List to store features for all images\n",
    "all_features = []\n",
    "\n",
    "# Iterate over images in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        # Load the image\n",
    "        image = cv2.imread(os.path.join(directory, filename), cv2.IMREAD_UNCHANGED)\n",
    "        \n",
    "        # Extract features\n",
    "        r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity = extract_features(image)\n",
    "        \n",
    "        # Determine grading based on filename\n",
    "        if filename.startswith(\"grade_A\"):\n",
    "            grading = \"A\"\n",
    "        elif filename.startswith(\"grade_B\"):\n",
    "            grading = \"B\"\n",
    "        elif filename.startswith(\"grade_C\"):\n",
    "            grading = \"C\"\n",
    "        else:\n",
    "            grading = \"Unknown\"\n",
    "        \n",
    "        all_features.append({\n",
    "            'grading': grading,\n",
    "            'R': r, \n",
    "            'G': g,\n",
    "            'B': b,\n",
    "            'H_HSV': h_hsv,\n",
    "            'S_HSV': s_hsv,\n",
    "            'V_HSV': v_hsv,\n",
    "            'H_HSI': h_hsi,\n",
    "            'S_HSI': s_hsi,\n",
    "            'I_HSI': i_hsi,\n",
    "            'CONTRAST': contrast,\n",
    "            'CORRELATION': correlation,\n",
    "            'ENERGY': energy,\n",
    "            'HOMOGENEITY': homogeneity\n",
    "        })\n",
    "\n",
    "# Now, all_features contains features for all images in the directory\n",
    "# print(all_features) \n",
    "\n",
    "# Convert all_features list to a DataFrame\n",
    "df = pd.DataFrame(all_features)\n",
    "\n",
    "# Save DataFrame to a CSV file\n",
    "df.to_csv('tuna_image_features.csv', index=False)\n",
    "\n",
    "print(\"csv file generated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7c3a60d-4bb6-4e9b-a638-210b9bd73c2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9315068493150684\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.95      0.94      0.94        95\n",
      "           B       0.93      0.88      0.90        91\n",
      "           C       0.92      0.97      0.94       106\n",
      "\n",
      "    accuracy                           0.93       292\n",
      "   macro avg       0.93      0.93      0.93       292\n",
      "weighted avg       0.93      0.93      0.93       292\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 89   3   3]\n",
      " [  5  80   6]\n",
      " [  0   3 103]]\n",
      "CPU times: total: 1.5 s\n",
      "Wall time: 1.8 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# importing libraries  \n",
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp  \n",
    "import pandas as pd  \n",
    "  \n",
    "#importing datasets  \n",
    "data_set= pd.read_csv('tuna_image_features.csv')  \n",
    "  \n",
    "#Extracting Independent and dependent Variable  \n",
    "x= data_set.iloc[:, [1,2,3,4,5,6,7,8,9,10,11,12,13]].values  \n",
    "y= data_set.iloc[:, 0].values  \n",
    "  \n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.20, random_state=42)  \n",
    "  \n",
    "#feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test) \n",
    "\n",
    "#Fitting K-NN classifier to the training set  \n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "classifier= KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2 )  \n",
    "classifier.fit(x_train, y_train)  \n",
    "\n",
    "#Predicting the test set result  \n",
    "y_pred= classifier.predict(x_test)\n",
    "\n",
    "#Creating the Confusion matrix  \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import joblib \n",
    "\n",
    "# Model Evaluation\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Additional Model Evaluation Metrics\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Step 7: Save the trained model and the scaler\n",
    "joblib.dump(classifier, 'knn_model.pkl')\n",
    "joblib.dump(st_x, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fdeb15c-a69e-4786-a74b-ae6d8ead445f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Grade: C\n"
     ]
    }
   ],
   "source": [
    "#input image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to open file explorer for picking an image\n",
    "def open_file_explorer():\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Hide the main window\n",
    "\n",
    "    # Open file explorer and return the selected file path\n",
    "    file_path = filedialog.askopenfilename()\n",
    "\n",
    "    if file_path:\n",
    "        # If a file is selected, classify the image\n",
    "        predicted_grade = classify_image(file_path)\n",
    "        print(\"Predicted Grade:\", predicted_grade)\n",
    "    else:\n",
    "        print(\"No file selected.\")\n",
    "\n",
    "# Call the function to open file explorer\n",
    "open_file_explorer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7840089a-e8ae-4121-8b99-d56ae6451660",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 287\u001b[0m\n\u001b[0;32m    285\u001b[0m input_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAsus\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool stuff\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124my 23-24\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2nd sem\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdes2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTuna_GRADES-20230522T082341Z-001\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTuna_GRADES\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTUNA GRADE A\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    286\u001b[0m output_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mAsus\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mOneDrive\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSchool stuff\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124my 23-24\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m2nd sem\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdes2\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTuna_GRADES-20230522T082341Z-001\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTuna_GRADES\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mTUNA GRADE A\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mval output\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 287\u001b[0m \u001b[43mclassify_images_in_folder\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mA done\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[32], line 280\u001b[0m, in \u001b[0;36mclassify_images_in_folder\u001b[1;34m(input_folder, output_folder)\u001b[0m\n\u001b[0;32m    277\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(input_folder, filename)\n\u001b[0;32m    279\u001b[0m \u001b[38;5;66;03m# Classify the image and save the classified image to the output folder\u001b[39;00m\n\u001b[1;32m--> 280\u001b[0m predicted_grade \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_and_save_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 240\u001b[0m, in \u001b[0;36mclassify_and_save_image\u001b[1;34m(image_path, output_folder)\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[38;5;66;03m# Extract features from the zoomed-in frame with foreground mask\u001b[39;00m\n\u001b[0;32m    239\u001b[0m     zoomed_fg_mask \u001b[38;5;241m=\u001b[39m fg_mask[y_zoom:y_zoom \u001b[38;5;241m+\u001b[39m zoom_size, x_zoom:x_zoom \u001b[38;5;241m+\u001b[39m zoom_size]\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m--> 240\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbitwise_and\u001b[49m\u001b[43m(\u001b[49m\u001b[43mzoomed_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mzoomed_fg_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;66;03m# Extract features\u001b[39;00m\n\u001b[0;32m    243\u001b[0m features \u001b[38;5;241m=\u001b[39m extract_features(zoomed_resized)\n",
      "Cell \u001b[1;32mIn[32], line 72\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(image)\u001b[0m\n\u001b[0;32m     69\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(rgb, cv2\u001b[38;5;241m.\u001b[39mCOLOR_RGB2GRAY)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# Convert RGB to HSI\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m hsi \u001b[38;5;241m=\u001b[39m \u001b[43mrgb_to_hsi\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# RGB\u001b[39;00m\n\u001b[0;32m     75\u001b[0m r, g, b \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(rgb[:,:,\u001b[38;5;241m0\u001b[39m]), np\u001b[38;5;241m.\u001b[39mmean(rgb[:,:,\u001b[38;5;241m1\u001b[39m]), np\u001b[38;5;241m.\u001b[39mmean(rgb[:,:,\u001b[38;5;241m2\u001b[39m])\n",
      "Cell \u001b[1;32mIn[32], line 54\u001b[0m, in \u001b[0;36mrgb_to_hsi\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hue\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m#Merge channels into picture and return image\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m hsi \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mmerge((\u001b[43mcalc_hue\u001b[49m\u001b[43m(\u001b[49m\u001b[43mred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgreen\u001b[49m\u001b[43m)\u001b[49m, calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hsi\n",
      "Cell \u001b[1;32mIn[32], line 42\u001b[0m, in \u001b[0;36mrgb_to_hsi.<locals>.calc_hue\u001b[1;34m(red, blue, green)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, blue\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, blue\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]):\n\u001b[0;32m     41\u001b[0m         hue[i][j] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m ((red[i][j] \u001b[38;5;241m-\u001b[39m green[i][j]) \u001b[38;5;241m+\u001b[39m (red[i][j] \u001b[38;5;241m-\u001b[39m blue[i][j])) \u001b[38;5;241m/\u001b[39m \\\n\u001b[1;32m---> 42\u001b[0m                     math\u001b[38;5;241m.\u001b[39msqrt((\u001b[43mred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m-\u001b[39m green[i][j])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m     43\u001b[0m                             ((red[i][j] \u001b[38;5;241m-\u001b[39m blue[i][j]) \u001b[38;5;241m*\u001b[39m (green[i][j] \u001b[38;5;241m-\u001b[39m blue[i][j])))\n\u001b[0;32m     44\u001b[0m         hue[i][j] \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39macos(hue[i][j])\n\u001b[0;32m     46\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m blue[i][j] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m green[i][j]:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#val A\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade = classify_and_save_image(image_path, output_folder)\n",
    "            # print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE A\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE A\\val output\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"A done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd4c497-8e68-483a-9ad0-d69fd148ffcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B done\n"
     ]
    }
   ],
   "source": [
    "#val B\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade = classify_and_save_image(image_path, output_folder)\n",
    "            # print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE B\\val output\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"B done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72375299-1004-4e3b-9255-ac64c7dd48ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B done\n"
     ]
    }
   ],
   "source": [
    "#val C\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "import os\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(image_path):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "     # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "    \n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image,(700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "        \n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "    \n",
    "        # Display the frame with bounding box\n",
    "        cv2.imshow('Frame with Bounding Box', image)\n",
    "\n",
    "        zoomed_resized = cv2.resize(zoomed_resized, (700, 700))\n",
    "        # Draw the outline of the text on the zoomed image\n",
    "        outline_thickness = 2\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "\n",
    "        # Draw the text on the zoomed image\n",
    "        cv2.putText(zoomed_resized, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Display the zoomed image with predicted grade\n",
    "        cv2.imshow('Zoomed In with Predicted Grade', zoomed_resized)\n",
    "    \n",
    "        # Wait for a key press to close the windows\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "# Function to classify an image and save the classified image\n",
    "def classify_and_save_image(image_path, output_folder):\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Apply background subtraction\n",
    "    fg_mask = bg_subtractor.apply(image)\n",
    "    fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "\n",
    "    # Perform adaptive thresholding to separate foreground from background\n",
    "    _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "    # Invert the thresholded image\n",
    "    thresholded = cv2.bitwise_not(thresholded)\n",
    "\n",
    "    # Find contours in the thresholded image\n",
    "    contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    if contours:\n",
    "        # Find the contour with the largest area\n",
    "        main_contour = max(contours, key=cv2.contourArea)\n",
    "\n",
    "        # Draw bounding box around the main contour\n",
    "        x, y, w, h = cv2.boundingRect(main_contour)\n",
    "        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "        # Zoom in to a specific area inside the bounding box\n",
    "        zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "        center_x = x + w // 2\n",
    "        center_y = y + h // 2\n",
    "        zoom_size = min(w, h) // zoom_factor\n",
    "        x_zoom = max(0, center_x - zoom_size // 2)\n",
    "        y_zoom = max(0, center_y - zoom_size // 2)\n",
    "        zoomed_image = image[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "        # Resize the zoomed image to 100x100 pixels\n",
    "        zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "\n",
    "        # Extract features from the zoomed-in frame with foreground mask\n",
    "        zoomed_fg_mask = fg_mask[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "        features = extract_features(cv2.bitwise_and(zoomed_image, zoomed_fg_mask))\n",
    "\n",
    "    # Extract features\n",
    "    features = extract_features(zoomed_resized)\n",
    "\n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "\n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "\n",
    "        image = cv2.resize(image, (800, 800))\n",
    "        # Draw the predicted grade on the image\n",
    "        cv2.putText(image, \"Predicted Grade: {}\".format(grade[0]), (10, 30),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "        # Save the classified image to the output folder\n",
    "        filename = os.path.basename(image_path)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        cv2.imwrite(output_path, image)\n",
    "\n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "\n",
    "# Function to classify images in a folder and save the classified images to another folder\n",
    "def classify_images_in_folder(input_folder, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate through each file in the input folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            # Construct the full path of the input image\n",
    "            image_path = os.path.join(input_folder, filename)\n",
    "\n",
    "            # Classify the image and save the classified image to the output folder\n",
    "            predicted_grade = classify_and_save_image(image_path, output_folder)\n",
    "            # print(\"Image:\", filename, \"- Predicted Grade:\", predicted_grade)\n",
    "\n",
    "\n",
    "# Call the function to classify images in the input folder and save the classified images to the output folder\n",
    "input_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE C\\validation\"\n",
    "output_folder = r\"C:\\Users\\Asus\\OneDrive\\Documents\\School stuff\\y 23-24\\2nd sem\\des2\\Tuna_GRADES-20230522T082341Z-001\\Tuna_GRADES\\TUNA GRADE C\\val output\"\n",
    "classify_images_in_folder(input_folder, output_folder)\n",
    "print(\"C done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a1f599-af88-4fe1-a8fd-a9cf6d7e8fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a49b1533-34da-406c-93c3-ae37122b9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(img):\n",
    "    global _grade\n",
    "    # Extract features\n",
    "    features = extract_features(img)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "        # print(grade)\n",
    "        _grade = grade\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "def main():\n",
    "    # Open the default camera (usually the built-in webcam)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "\n",
    "    # Check if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    # Create a background subtractor object\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame was captured successfully\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "        # Apply background subtraction\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "\n",
    "        # Find contours in the foreground mask\n",
    "        contours, _ = cv2.findContours(fg_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the largest contour (if any)\n",
    "        largest_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "\n",
    "        # Draw bounding box around the largest contour (if any)\n",
    "        if largest_contour is not None:\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Zoom in to a specific area inside the bounding box\n",
    "            zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            zoom_size = min(w, h) // zoom_factor\n",
    "            x_zoom = max(0, center_x - zoom_size // 2)\n",
    "            y_zoom = max(0, center_y - zoom_size // 2)\n",
    "            zoomed_image = frame[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "            \n",
    "            try:\n",
    "                # Resize the zoomed image to 100x100 pixels\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (400, 400))\n",
    "                cv2.imshow('Zoomed Bounding Box', zoomed_resized)\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "                classify_image(zoomed_resized)\n",
    "                # Draw the outline of the text on the zoomed image\n",
    "                outline_thickness = 2\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "                \n",
    "                # Draw the text on the zoomed image\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                # print(f\"grade = {_grade}\")\n",
    "            except:\n",
    "                 pass\n",
    "\n",
    "        # Display the frame with bounding box (if any)\n",
    "        cv2.imshow('Largest Foreground Object', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affc145d-8788-4eec-9359-0ae7bc39b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#webcam2\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.feature import graycomatrix, graycoprops\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import math\n",
    "\n",
    "def rgb_to_hsi(img):\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "\n",
    "        #Load image with 32 bit floats as variable type\n",
    "        bgr = np.float32(img)/255\n",
    "\n",
    "        #Separate color channels\n",
    "        blue = bgr[:,:,0]\n",
    "        green = bgr[:,:,1]\n",
    "        red = bgr[:,:,2]\n",
    "\n",
    "        #Calculate Intensity\n",
    "        def calc_intensity(red, blue, green):\n",
    "            return np.divide(blue + green + red, 3)\n",
    "\n",
    "        #Calculate Saturation\n",
    "        def calc_saturation(red, blue, green):\n",
    "            minimum = np.minimum(np.minimum(red, green), blue)\n",
    "            saturation = 1 - (3 / (red + green + blue + 0.001) * minimum)\n",
    "\n",
    "            return saturation\n",
    "\n",
    "        #Calculate Hue\n",
    "        def calc_hue(red, blue, green):\n",
    "            hue = np.copy(red)\n",
    "\n",
    "            for i in range(0, blue.shape[0]):\n",
    "                for j in range(0, blue.shape[1]):\n",
    "                    hue[i][j] = 0.5 * ((red[i][j] - green[i][j]) + (red[i][j] - blue[i][j])) / \\\n",
    "                                math.sqrt((red[i][j] - green[i][j])**2 +\n",
    "                                        ((red[i][j] - blue[i][j]) * (green[i][j] - blue[i][j])))\n",
    "                    hue[i][j] = math.acos(hue[i][j])\n",
    "\n",
    "                    if blue[i][j] <= green[i][j]:\n",
    "                        hue[i][j] = hue[i][j]\n",
    "                    else:\n",
    "                        hue[i][j] = ((360 * math.pi) / 180.0) - hue[i][j]\n",
    "\n",
    "            return hue\n",
    "\n",
    "        #Merge channels into picture and return image\n",
    "        hsi = cv2.merge((calc_hue(red, blue, green), calc_saturation(red, blue, green), calc_intensity(red, blue, green)))\n",
    "        return hsi\n",
    "\n",
    "def extract_features(image):\n",
    "        #if zero dont input\n",
    "        if np.any(image!=[0,0,0]):\n",
    "            rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            # Normalize RGB values to [0, 1] for accurate HSV conversion\n",
    "            rgb_normalized = rgb.astype(np.float32) / 255.0\n",
    "    \n",
    "            # Convert RGB to HSV\n",
    "            hsv = cv2.cvtColor(rgb_normalized, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "            # Convert to grayscale for GLCM\n",
    "            gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "            # Convert RGB to HSI\n",
    "            hsi = rgb_to_hsi(image)\n",
    "\n",
    "            # RGB\n",
    "            r, g, b = np.mean(rgb[:,:,0]), np.mean(rgb[:,:,1]), np.mean(rgb[:,:,2])\n",
    "        \n",
    "            # HSV\n",
    "            h_hsv, s_hsv, v_hsv = np.mean(hsv[:,:,0]), np.mean(hsv[:,:,1]), np.mean(hsv[:,:,2])\n",
    "        \n",
    "            # HSI (HLS approximation)\n",
    "            h_hsi, s_hsi, i_hsi = np.mean(hsi[:,:,0]), np.mean(hsi[:,:,1]), np.mean(hsi[:,:,2])\n",
    "        \n",
    "            # GLCM\n",
    "            glcm = graycomatrix(gray, distances=[1], angles=[0, np.pi/4, np.pi/2, 3*np.pi/4],\n",
    "                                 symmetric=True, normed=True)\n",
    "            contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "            correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "            energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "            homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "        \n",
    "            return r, g, b, h_hsv, s_hsv, v_hsv, h_hsi, s_hsi, i_hsi, contrast, correlation, energy, homogeneity\n",
    "        else: \n",
    "            return None, None, None, None\n",
    "\n",
    "# Load the trained K-NN model and scaler\n",
    "knn_model = joblib.load('knn_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "# Create background subtractor\n",
    "bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "# Function to classify an image\n",
    "def classify_image(img):\n",
    "    global _grade\n",
    "    # Extract features\n",
    "    features = extract_features(img)\n",
    "    \n",
    "    if features is not None:\n",
    "        # Scale the features\n",
    "        scaled_features = scaler.transform([features])\n",
    "        \n",
    "        # Predict the grade\n",
    "        grade = knn_model.predict(scaled_features)\n",
    "        # print(grade)\n",
    "        _grade = grade\n",
    "        \n",
    "        return grade[0]\n",
    "    else:\n",
    "        return \"Error: Unable to extract features from the image.\"\n",
    "\n",
    "def main():\n",
    "    # Set desired camera resolution\n",
    "    desired_width = 1280\n",
    "    desired_height = 720\n",
    "    # Open the default camera (usually the built-in webcam)\n",
    "    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n",
    "    cap.set(cv2.CAP_PROP_SETTINGS, 1)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, desired_width)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, desired_height)\n",
    "\n",
    "    # Check if the camera is opened successfully\n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open camera.\")\n",
    "        return\n",
    "\n",
    "    # Create a background subtractor object\n",
    "    bg_subtractor = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "    while True:\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame was captured successfully\n",
    "        if not ret:\n",
    "            print(\"Error: Failed to capture frame.\")\n",
    "            break\n",
    "\n",
    "         # Apply background subtraction\n",
    "        fg_mask = bg_subtractor.apply(frame)\n",
    "        fg_mask = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "        # Convert the image to grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Apply Gaussian blur to reduce noise\n",
    "        blurred = cv2.GaussianBlur(gray, (31, 31), 0)\n",
    "    \n",
    "        # Perform adaptive thresholding to separate foreground from background\n",
    "        _, thresholded = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "        # Invert the thresholded image\n",
    "        thresholded = cv2.bitwise_not(thresholded)\n",
    "    \n",
    "        # Find contours in the thresholded image\n",
    "        contours, _ = cv2.findContours(thresholded, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Find the largest contour (if any)\n",
    "        largest_contour = max(contours, key=cv2.contourArea, default=None)\n",
    "\n",
    "        # Draw bounding box around the largest contour (if any)\n",
    "        if largest_contour is not None:\n",
    "            x, y, w, h = cv2.boundingRect(largest_contour)\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "            # Zoom in to a specific area inside the bounding box\n",
    "            zoom_factor = 3  # Adjust the zoom factor as needed\n",
    "            center_x = x + w // 2\n",
    "            center_y = y + h // 2\n",
    "            zoom_size = min(w, h) // zoom_factor\n",
    "            x_zoom = max(0, center_x - zoom_size // 2)\n",
    "            y_zoom = max(0, center_y - zoom_size // 2)\n",
    "            zoomed_image = frame[y_zoom:y_zoom + zoom_size, x_zoom:x_zoom + zoom_size].copy()\n",
    "\n",
    "            try:\n",
    "                # Resize the zoomed image to 100x100 pixels\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (400, 400))\n",
    "                cv2.imshow('Zoomed Bounding Box', zoomed_resized)\n",
    "                zoomed_resized = cv2.resize(zoomed_image, (32, 32))\n",
    "                classify_image(zoomed_resized)\n",
    "                # Draw the outline of the text on the zoomed image\n",
    "                outline_thickness = 2\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 0), outline_thickness + 2)\n",
    "                \n",
    "                # Draw the text on the zoomed image\n",
    "                cv2.putText(frame, \"Predicted Grade: {}\".format(_grade), (10, 30),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "                # print(f\"grade = {_grade}\")\n",
    "            except:\n",
    "                 pass\n",
    "\n",
    "        # Display the frame with bounding box (if any)\n",
    "        cv2.imshow('Largest Foreground Object', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the camera and close the windows\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "#webcam2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c00b6-2ecb-45f5-beca-43d92047825b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
